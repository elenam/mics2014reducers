% This is sigproc-sp.tex -FILE FOR V2.6SP OF ACM_PROC_ARTICLE-SP.CLS
% OCTOBER 2002
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V2.6SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.6SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
%
%  However, both the CopyrightYear (default to 2002) and the ACM Copyright Data
% (default to X-XXXXX-XX-X/XX/XX) can still be over-ridden by whatever the author
% inserts into the source .tex file.
% e.g.
% \CopyrightYear{2003} will cause 2003 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@acm.org 
%
% For tracking purposes - this is V2.6SP - OCTOBER 2002

\documentclass[12pt]{article}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textwidth}{6in}
\setlength{\textheight}{9in}
\setlength{\parindent}{0in} 

\usepackage{graphicx} %For jpg figure inclusion
\usepackage{times} %For typeface
\usepackage{epsfig}
\usepackage{color} %For Comments
\usepackage[all]{xy}
\usepackage{float}
\usepackage{subfigure} 
\usepackage{hyperref}
\usepackage{url}
\usepackage{parskip}


%% Elena's favorite green (thanks, Fernando!)
\definecolor{ForestGreen}{RGB}{34,139,34}
\definecolor{JoesGold}{RGB}{204,102,0}
% Uncomment this if you want to show work-in-progress comments
\newcommand{\comment}[1]{{\bf \tt  {#1}}}
% Uncomment this if you don't want to show comments
%\newcommand{\comment}[1]{}
\newcommand{\emcomment}[1]{\textcolor{ForestGreen}{\comment{Elena: {#1}}}}
\newcommand{\joecomment}[1]{\textcolor{JoesGold}{\comment{Joe: {#1}}}}
\newcommand{\todo}[1]{\textcolor{blue}{\comment{To Do: {#1}}}}
\newcommand{\hfcomment}[1]{\textcolor{Teal}{\comment{Henry: {#1}}}}
\newcommand{\clocode}[1]{{\texttt {#1}}}
%% Henry's color
\definecolor{Teal}{RGB}{2,132,130}

\begin{document}
\pagestyle{plain}
%
% --- Author Metadata here ---
%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\setpagenumber{50}
%\CopyrightYear{2002} % Allows default copyright year (2002) to be
%over-ridden - IF NEED BE. 
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data
%(X-XXXXX-XX-X/XX/XX) to be over-ridden. 
% --- End of Author Metadata ---




\title{Exploration of parallelization efficiency in the Clojure programming language}
%\subtitle{[Extended Abstract \comment{DO WE NEED THIS?}]
%\titlenote{}}
%
% You need the command \numberofauthors to handle the "boxing"
% and alignment of the authors under the title, and to add
% a section for authors number 4 through n.
%
% Up to the first three authors are aligned under the title;
% use the \alignauthor commands below to handle those names
% and affiliations. Add names, affiliations, addresses for
% additional authors as the argument to \additionalauthors;
% these will be set for you without further effort on your
% part as the last section in the body of your article BEFORE
% References or any Appendices.




\author{
Henry Fellows, Joe Einertson, and Elena Machkasova \\
Computer Science Discipline \\
University of Minnesota Morris\\
Morris, MN 56267\\
??, ??, elenam@umn.edu
}




\date{}




\maketitle
\thispagestyle{empty}


\section*{\centering Abstract}
In modern processing environments, parallelism is becoming an increasingly important tool in making gains in software performance. Despite the importance of parallelism, it is often poorly supported, or awkward to use effectively. The most common approach to concurrency is the mutable state model, where threads can attempt to read or write the value of a shared resource. This approach, while it may be more efficient, can cause problems such as deadlocking - a state where two threads are both waiting for a resource that the other task holds. In immutable state systems, this is prevented by having the thread create an instance of the resource as soon as it is able to access the resource.


Clojure is a Lisp dialect designed for concurrency and portability by Rich Hickey, first released in late 2007. Clojure runs on the Java Virtual Machine (JVM), and features immutable data structures along with other tools to make concurrent development easier. Immutable data structures do not present problems stemming from sharing the same memory. Clojure has proven to provide high efficiency of parallel processing. In 2012 clojure.core.reducers was added to the language: a novel library that contains a set of high level functions for an even more convenient and efficient parallel processing of data collections. Clojure originally had an earlier version of this functionality in pmap, a parallel version of map, a built in function that traverses Clojure collections. Clojure includes many utilities that are implemented using significantly different methods. Reducers are based on the Java Fork/Join framework, while pmap uses the Java Futures library.


In this study, we focus on testing the various methods of parallel processing in Clojure and explore the functionality of the reducers library. Timing the execution of computationally expensive and highly parallelizable data processing allows us to directly observe the differences between different methods of parallelism provided in Clojure. In order to time the execution we used a Clojure utility that allows access to the system clock. We created a function that records the system time, executes a given function, and then returns the elapsed time.


We have found that both \clocode{pmap} and reducers decrease the execution time by a factor of the number of cores, as expected. Reducers were found to provide a significant performance gain, in all situations, over \clocode{pmap}. We also studied the distribution of load across multiple cores, and the scaling of the execution time as data size increases. We present the results, analysis, and conclusions.
\emcomment{As submitted to MICS; needs to be changed}


 %\newpage
%this causes problems when compiling.

\setcounter{page}{1}


\section{Introduction}\label{sec:intro}




\section{Background}\label{sec:background}




\subsection{Clojure}\label{sec:clojure}
Clojure was developed and first introduced in 2007 by Rich Hickey~\cite{Hickey:2008}. Clojure is a dialect of Lisp designed for concurrency and portability that runs on the Java virtual machine. Leveraging the widespread nature of the jvm, Clojure can run on any \hfcomment{is that true?} environment that supports the JVM. 

The Lisp family of languages have several features in common, the most visible of which is the polish-prefix notation. Cojure, as a lisp, uses the polish-prefix notation, which can be generalized to \clocode{(function arg1 arg2 ... argN)}. For example, 
\begin{verbatim}
(+ 2 3)
=> 5
\end{verbatim}
Functions in Lisp are created using the \clocode{defn} macro. It is useful to note that \clocode{defn} is short for \clocode{def} (define) \clocode{fn}, where fn is a common abbreviation of function in the Lisp community.
\hfcomment{Fishing for feedback on the above line - I don't like it.}
\begin{verbatim}
(defn add1 [num] (+ num 1))
(add1 4)
=> 5
\end{verbatim}
 Lisps also have a philosophy of treating code as data, meaning that all functions can take functions (or other code) as arguments
\begin{verbatim}
(defn apply-fn [a-function an-arg] (a-function an-arg))
(apply-fn add1 4)
=> 5
\end{verbatim}
Because of that philosophy, most Lisps, including Clojure, provide a rich set of higher-order functions that allow for powerful manipulation of data. Clojure includes \clocode{map}, a function that takes a function and a collection and then applies the function to every item in the collection.
\begin{verbatim}
(map add1 '(0 1 2 3 4))
=>'(1 2 3 4 5)
\end{verbatim}
Clojure also includes \clocode{reduce}, also known as fold in other Lisps, which applies the given function to the first two items in a collection. It then takes the result and applies the function to the result and the next item in the collection, repeating this process until the collection is empty.
\begin{verbatim}
(reduce +  '(1 2 3))
=>6
\end{verbatim}
The next of the major high-order functions is filter, which takes a predicate (a function that returns a boolean and has no side-effects) and a collection and returns a new collection of the items in the original collection for which the predicate (when applied to the item) returns true.
\begin{verbatim}
(filter even? '(1 2 3 4 5))
=> '(2 4)
\end{verbatim}
\emcomment{Need: prefix syntax, explain higher order functions, explain map, reduce, fold, filter. Explain vectors (briefly) since our stuff only works on vectors}


\subsection{Introduction to concurrency}\label{sec:concurrency}




\subsection{Introduction to pmap}\label{sec:pmap}




\subsection{Introduction to reducers}\label{sec:reducers}
Reducers library was released by Rich Hickey in May 2012~\cite{HickeyReducers}. 

\section{Efficiency of parallel methods in Clojure}\label{sec:efficiency}

\subsection{Test Methodology}\label{sec:methods}
 
\emcomment{Need background on JVM warmup (and some background on JVM)}

\subsection{Fermat primality test}\label{sec:fermat}
Two of the tests described rely, at least in part, on determining which numbers in the collection are prime \emcomment{I wouldn't say they rely on it. Centered on?}. Specifically, we use a probabilistic algorithm called the \emph{Fermat primality test}, which takes two parameters: a number to test for primality, and an integer that determines the number of trials to be run. The higher the number of trials, the more precise the result and the more processing power used. We use 5 trials per number, which gives a high degree of accuracy for a moderate amount of processing power.

The Fermat primality test relies heavily on exponentiation and modular arithmetic, operations which are relatively expensive for large numbers. The specific mathematics behind the Fermat primality test are tangential to and beyond the scope of this paper. It is only necessary to understand that we chose this test because it is simple to implement, computationally expensive, and an example of a real-world operation which may benefit from Clojure's reducers.
\emcomment{Would it be useful to mention that the test makes calls to Java library functions and uses bigint (if it indeed uses bigints)?}

\subsubsection{Compare-Count-Primes}\label{sec:count-primes}
\joecomment{Do we want to say the specific sizes used? 250 runs, 10k coll size, 1b max ele size}
\emcomment{yes}
The first test we describe is an algorithm to determine the number of prime numbers in a large collection of very large numbers \emcomment{randomly generated}. In the baseline implementation, we use a simple reduce operation to count the number of primes:

\begin{verbatim}
(defn reduce-num-primes
  [a b] (if (p/fermat-test b 5)
         (inc a)
         a))
\end{verbatim}

Simply, for each element which is found to be prime via the Fermat primality test, we increase the running sum of primes by one (starting from 0). This implementation leverages r/fold, meaning it is a parallel reduce operation. 
\emcomment{We need to introduce our setup before this, and then just refer to this implementation as the one suitable for map, and the fold-only implementation as something else. I think it's very unclear in this description what's going on and it wouldn't be clear until we explain the goals and the cases of test runs (reduce/map, reduce/pmap, etc)}
%\emcomment{I am confused: didn't we run all tests with all possible combinations of map/reduce(r/fold)?}

We also tested the pure r/fold implementation against ones that used r/fold only for parallel summation, and computed the primality of values using map or parallel map. In this case, we used this mapping function:

\begin{verbatim}
(defn count-primes-pre-reducer
  [x] (if (p/fermat-test x 5) 1 0))
\end{verbatim}

Here the work of determining the primality of the numbers is moved into a mapping operation, which returns 1 for each element if prime, or 0 if not. Then we use r/fold to sum the result in parallel. This is simpler from an implementation standpoint, as our mapping function does not have to conform to the restrictions of r/fold, and summation is trivial to use with r/fold.

  
\subsubsection{Compare-Sum-Primes}\label{sec:sum-primes}
The second test we describe is broadly similar to compare-count-primes, but sums the value of all primes (ignoring composite numbers) rather than simply counting them. This is a more computationally expensive test, since the numbers being summed are very large, rather than 0's and 1's. The purpose of this test is to add computational complexity to the r/fold portion to determine what effect the distribution of work has on running time.

As with compare-count-primes, there is a basic, all-in-one reduce function:

\begin{verbatim}
(defn reduce-sum-primes
  [a b] (if (p/fermat-test b 5)
         (+' a b)
         a))
\end{verbatim}

Additionally, as with compare-count-primes, we split the test into two parts for further analysis: one part run with map or pmap, and a second combining part run with r/fold. Our pre-reduction mapping function is similarly simple:

\begin{verbatim}
(defn sum-primes-pre-reducer
  [x] (if (p/fermat-test x 5) x 0))
\end{verbatim}
 
 \subsubsection{Compare-Sum-Sqrt}\label{sec:sum-sqrt}
 
 \hfcomment{info about how this test works}
 
 \subsection{Execution Methodology}\label{sec:eMethods}
 Following the method shown above, we ran the tests on several different machines referred to as box1, box2, and box3.
 
\begin{itemize}
 \item 
 Box 1 has a Intel i7 (4700MQ) cpu, with 4 hyperthreaded cores, running Windows 7.
 \item
 Box 2 has a Intel i5 (650) cpu, with 4 cores, running Fedora 18.
 \item
 Box 3 has a xyz cpu, with q cores, running foo OS. Box 1 has a xzy cpu, with q cores, running foo OS.
 \end{itemize}
  
The full set of tests was run three times on each machine. The first run is discarded due to Java virtual machine warm-up, a period where the program runs significantly slower than it would normally ~\cite{Blackburn:2008} . This period is caused by the JVM preforming dynamic optimization and lazy loading relevant portions of code. In order to provide data that is unambiguous and easy to interpret, we omit that portion of the data from the results. It is important to note that the ratio between each portion of a test remained constant.




\subsection{Tests}\label{sec:tests}
\emcomment{Describe the tests. Joe, this should be your section for the most part, although Henry changed some of the outputs and added more cases}

\emcomment{Need to explain why we aren't using a filter here for primality testing examples: for consistency with pmap?}

\subsection{Results}\label{sec:results}
In this section we show the results of running our tests across the machines mentioned above;
\hfcomment{I'll be putting the carts \& tables here - I'm still working on the spreadsheets}


\subsection{Discussion}\label{sec:discussion}
We have found that both \clocode{pmap} and reducers decrease the execution time from a serial method by a factor of the number of cores, as expected. The Reducers library was found to provide a significant performance gain, in all situations, over \clocode{pmap}. The average gain was x\%, with a range from a\% to b\%.




\section{Conclusions and future work}\label{sec:conclusion}




\subsection{Future Work}\label{sec:future}








%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
%\bibliographystyle{abbrv}
%\end{thebibliography}




%\bibliography{generic_types}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
\bibliographystyle{abbrv}
\bibliography{mics2014reducers}








% That's all folks!
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
